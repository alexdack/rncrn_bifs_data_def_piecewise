{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1817971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.io\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from scipy.special import jv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "513f0294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the filename to save the weights of the model as a .mat\n",
    "filename = 'models/homoclinic_1'\n",
    "\n",
    "# define the interval of the domain for the visible dynamics\n",
    "lower_limit = 3.5\n",
    "upper_limit = 6.5\n",
    "\n",
    "param_lower_limit = -1\n",
    "param_upper_limit = 1\n",
    "\n",
    "step_size = 0.015;\n",
    "step_size_par = 0.25;\n",
    "\n",
    "# define the approximate size the small offset parameter in the smooth ReLU\n",
    "gamma = 1\n",
    "\n",
    "# define the approximate size the feedback offset parameter in the feedback motif\n",
    "beta_1 = 260\n",
    "alpha = 1;\n",
    "\n",
    "# define the number of hidden species in a single hidden layer\n",
    "N = 10;\n",
    "\n",
    "# bifurication center\n",
    "a = 5;\n",
    "\n",
    "# define the number of epochs to use in training the model\n",
    "number_of_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3f0e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the custom activation function for the training with particular values of the relu_offset\n",
    "def smooth_max_activation(x):\n",
    "    return 0.5*(x + K.sqrt(K.square(x)+4*gamma*tau))/tau\n",
    "\n",
    "get_custom_objects().update({'smooth_max_activation': Activation(smooth_max_activation)})\n",
    "\n",
    "\n",
    "#define data\n",
    "x1_train = np.arange(lower_limit, upper_limit, step_size, dtype=\"float32\")\n",
    "x2_train = np.arange(lower_limit, upper_limit, step_size, dtype=\"float32\")\n",
    "x3_train = np.arange(param_lower_limit, param_upper_limit, step_size_par, dtype=\"float32\")\n",
    "\n",
    "x1v, x2v, x3v = np.meshgrid(x1_train, x2_train, x3_train, indexing='ij')\n",
    "\n",
    "nx1 = len(x1_train)\n",
    "nx2 = len(x2_train)\n",
    "nx3 = len(x3_train)\n",
    "\n",
    "g_1 = (x3v-(4/5))*(x1v-a)+(x2v-a)-(6/5)*(x1v-a)*(x2v-a)+(3/2)*pow((x2v-a),2)\n",
    "g_2 = (x1v-a) -(4/5)*(x2v-a) - (4/5)*pow((x2v-a),2)\n",
    "\n",
    "y1_train = (g_1 - beta_1)/x1v\n",
    "y2_train = (g_2 - beta_1)/x2v\n",
    "\n",
    "x_train = np.append(np.append(x1v.reshape(-1,1), x2v.reshape(-1,1),axis=1), x3v.reshape(-1,1),axis=1)\n",
    "y_train = np.append(y1_train.reshape(-1,1), y2_train.reshape(-1,1),axis=1)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e066083",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "Exception encountered when calling layer 'activation' (type Activation).\n\nname 'tau' is not defined\n\nCall arguments received by layer 'activation' (type Activation):\n  • inputs=tf.Tensor(shape=(None, 10), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# define a neural network model that corresponds to the asymptotic neural subsytem \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFlatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msmooth_max_activation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# compile model with optimizer and choice of loss function\u001b[39;00m\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     11\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m, in \u001b[0;36msmooth_max_activation\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msmooth_max_activation\u001b[39m(x):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39m(x \u001b[38;5;241m+\u001b[39m K\u001b[38;5;241m.\u001b[39msqrt(K\u001b[38;5;241m.\u001b[39msquare(x)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m4\u001b[39m\u001b[38;5;241m*\u001b[39mgamma\u001b[38;5;241m*\u001b[39m\u001b[43mtau\u001b[49m))\u001b[38;5;241m/\u001b[39mtau\n",
      "\u001b[1;31mNameError\u001b[0m: Exception encountered when calling layer 'activation' (type Activation).\n\nname 'tau' is not defined\n\nCall arguments received by layer 'activation' (type Activation):\n  • inputs=tf.Tensor(shape=(None, 10), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# define a neural network model that corresponds to the asymptotic neural subsytem \n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(3,), name=''),\n",
    "  tf.keras.layers.Dense(N, activation='smooth_max_activation'),\n",
    "  tf.keras.layers.Dense(2, activation=None, use_bias=False),\n",
    "])\n",
    "\n",
    "# compile model with optimizer and choice of loss function\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67b44c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the neural network model to replicate x_train -> y_train\n",
    "model.fit(x_train, y_train, epochs=number_of_epochs, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e743e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the model structure, each 'Param' corresponds to at least one rate of reaction in the chemical system\n",
    "model.summary()\n",
    "\n",
    "# save the weights of this neural network for use in ODE simulations in MATLAB\n",
    "first_layer_weights = model.layers[1].get_weights()[0]\n",
    "first_layer_biases = model.layers[1].get_weights()[1]\n",
    "output_layer_weights = model.layers[2].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f08cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat(filename+'.mat', {'first_layer_weights':first_layer_weights, \n",
    "                                   'first_layer_biases':first_layer_biases, \n",
    "                                   'output_layer_weights':output_layer_weights,\n",
    "                                   'gamma': gamma,\n",
    "                                   'beta': beta_1,\n",
    "                                   'alpha': alpha\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ef655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
