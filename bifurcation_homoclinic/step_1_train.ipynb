{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1817971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "import scipy.io\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "513f0294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the filename to save the weights of the model as a .mat\n",
    "filename = 'models/homoclinic_1'\n",
    "\n",
    "# define the subset of the (x_1,x_2)-space to approximate dynamics\n",
    "x1_lower_limit = 3.5\n",
    "x1_upper_limit = 6.5\n",
    "x2_lower_limit = 3.5\n",
    "x2_upper_limit = 6.5\n",
    "step_size = 0.01;\n",
    "\n",
    "# define the interval of the parameter species\n",
    "param_lower_limit = 1.9\n",
    "param_upper_limit = 2.1\n",
    "step_size_par = 0.1;\n",
    "\n",
    "# hardcode the gamma, beta, tau and  constants in the chemical perceptron (later examples automatically train this parameter)\n",
    "# Note -  tau corresponds to the scaling of  -tau*y^2 (see Appendix B - (32) & (33))\n",
    "gamma = 1\n",
    "beta_1 = 1\n",
    "tau = 1;\n",
    "\n",
    "# define the number of chemical perceptrons species in a single hidden layer\n",
    "N = 10;\n",
    "\n",
    "# bifurication center and critical point\n",
    "a = 5;\n",
    "r_critical = 2\n",
    "\n",
    "# define the number of epochs to use in training the model\n",
    "number_of_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3f0e882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the custom activation function for the training with particular values of gamma and tau \n",
    "def smooth_max_activation(x):\n",
    "    return 0.5*(x + K.sqrt(K.square(x)+4*gamma*tau))/tau\n",
    "\n",
    "get_custom_objects().update({'smooth_max_activation': Activation(smooth_max_activation)})\n",
    "\n",
    "# define training for the executive species and parameter species\n",
    "x1_train = np.arange(x1_lower_limit, x1_upper_limit, step_size, dtype=\"float32\")\n",
    "x2_train = np.arange(x2_lower_limit, x2_upper_limit, step_size, dtype=\"float32\")\n",
    "x3_train = np.arange(param_lower_limit, param_upper_limit, step_size_par, dtype=\"float32\")\n",
    "\n",
    "x1v, x2v, x3v = np.meshgrid(x1_train, x2_train, x3_train, indexing='ij')\n",
    "\n",
    "nx1 = len(x1_train)\n",
    "nx2 = len(x2_train)\n",
    "nx3 = len(x3_train)\n",
    "\n",
    "# compute the target ODE i.e. shifted from this paper https://doi.org/10.1007/s11071-025-11622-1\n",
    "g_1 = (x3v-r_critical-(4/5))*(x1v-a)+(x2v-a)-(6/5)*(x1v-a)*(x2v-a)+(3/2)*np.power((x2v-a),2)\n",
    "g_2 = (x1v-a) -(4/5)*(x2v-a) - (4/5)*np.power((x2v-a),2)\n",
    "\n",
    "# according to Algorithm 1 in https://doi.org/10.48550/arXiv.2406.03456\n",
    "y1_train = (g_1 - beta_1)/x1v\n",
    "y2_train = (g_2 - beta_1)/x2v\n",
    "\n",
    "# process the array shapes \n",
    "x_train = np.append(np.append(x1v.reshape(-1,1), x2v.reshape(-1,1),axis=1), x3v.reshape(-1,1),axis=1)\n",
    "y_train = np.append(y1_train.reshape(-1,1), y2_train.reshape(-1,1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e066083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the quasi-static approxiamtion according to Algorithm 1 in https://doi.org/10.48550/arXiv.2406.03456\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(3,), name=''),\n",
    "  tf.keras.layers.Dense(N, activation='smooth_max_activation'),\n",
    "  tf.keras.layers.Dense(2, activation=None, use_bias=False),\n",
    "])\n",
    "\n",
    "# compile model with an optimizer and mse loss function\n",
    "model.compile(optimizer='adamax',\n",
    "              loss='mse',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b67b44c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7594/7594 [==============================] - 8s 1ms/step - loss: 0.1631 - mse: 0.1631 - val_loss: 0.0485 - val_mse: 0.0485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1746ae96b30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the qusai-static neural network model to replicate x_train -> y_train\n",
    "model.fit(x_train, y_train, epochs=number_of_epochs, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e743e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      "  (Flatten)                  (None, 3)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                40        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60 (240.00 Byte)\n",
      "Trainable params: 60 (240.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# view the model structure, each 'Param' corresponds to at least one rate of reaction in the chemical system\n",
    "model.summary()\n",
    "\n",
    "# save the weights of this neural network for use in ODE simulations in MATLAB\n",
    "first_layer_weights = model.layers[1].get_weights()[0]\n",
    "first_layer_biases = model.layers[1].get_weights()[1]\n",
    "output_layer_weights = model.layers[2].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7f08cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat(filename+'.mat', {'first_layer_weights':first_layer_weights, \n",
    "                                   'first_layer_biases':first_layer_biases, \n",
    "                                   'output_layer_weights':output_layer_weights,\n",
    "                                   'gamma': gamma,\n",
    "                                   'beta': beta_1,\n",
    "                                   'alpha': tau #abuse of notation - still refering to tau  \n",
    "                                  })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
